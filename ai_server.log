/home/i0179/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
INFO:__main__:Starting Reality Lab Qwen3-4B Server (4-bit) on port 4005...
INFO:__main__:Loading Qwen3-4B tokenizer from local path
INFO:__main__:Loading Qwen3-4B model with 4-bit quantization
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:07,  3.89s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:08<00:04,  4.32s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.40s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.88s/it]
INFO:__main__:âœ… Qwen3-4B model loaded successfully with 4-bit quantization
INFO:__main__:Model vocab size: 151936, Tokenizer vocab size: 151669
INFO:__main__:PAD token ID: 151643, EOS token ID: 151645
INFO:__main__:Loading RAG system...
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
INFO:__main__:âœ… RAG system loaded successfully!
INFO:__main__:â±ï¸  Idle timeout enabled: server will shutdown after Nones of inactivity
INFO:__main__:ðŸš€ Qwen3-4B server ready on port 4005!
INFO:__main__:âœ… Running with HTTP (no SSL)
Loading Hierarchical RAG from: /home/i0179/Realitylab-site/ai_server/hierarchical_rag
  Loading embedding model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
  âœ… faculty: 2 docs
  âœ… students: 23 docs
  âœ… alumni: 17 docs
  âœ… news: 18 docs
  âœ… publications: 32 docs
  âœ… lab_info: 1 docs
âœ… Hierarchical RAG ready!
 * Serving Flask app 'qwen3_4b_lowmem'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:4005
 * Running on http://203.253.25.165:4005
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:20:46] "OPTIONS /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:20:46] "POST /heartbeat HTTP/1.1" 200 -
INFO:__main__:Original query: ê¹€ë„ì›ì´ ë‚¸ ë…¼ë¬¸ì€?
INFO:__main__:Cleaned query: ê¹€ë„ì› ë‚¸ ë…¼ë¬¸ì€?
[Query Classification] Searching categories: ['publications']
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.94it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.93it/s]
INFO:__main__:RAG found 5 documents
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:21:17] "OPTIONS /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:21:17] "POST /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:21:21] "OPTIONS /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:21:21] "POST /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:21:46] "OPTIONS /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:21:46] "POST /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:21:47] "POST /chat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:22:17] "OPTIONS /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:22:17] "POST /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:22:21] "OPTIONS /heartbeat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 20:22:21] "POST /heartbeat HTTP/1.1" 200 -
