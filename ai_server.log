/home/i0179/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
INFO:__main__:Starting Reality Lab Qwen3-4B Server (4-bit) on port 4005...
INFO:__main__:Loading Qwen3-4B tokenizer from local path
INFO:__main__:Loading Qwen3-4B model with 4-bit quantization
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:04<00:08,  4.39s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:09<00:04,  4.73s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  2.62s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.16s/it]
INFO:__main__:âœ… Qwen3-4B model loaded successfully with 4-bit quantization
INFO:__main__:Model vocab size: 151936, Tokenizer vocab size: 151669
INFO:__main__:PAD token ID: 151643, EOS token ID: 151645
INFO:__main__:Loading RAG system...
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
INFO:__main__:âœ… RAG system loaded successfully!
INFO:__main__:â±ï¸  Idle timeout enabled: server will shutdown after 120s of inactivity
INFO:__main__:ðŸš€ Qwen3-4B server ready on port 4005!
INFO:__main__:âœ… Running with HTTP (no SSL)
Loading Hierarchical RAG from: /home/i0179/Realitylab-site/ai_server/hierarchical_rag
  Loading embedding model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
  âœ… faculty: 2 docs
  âœ… students: 23 docs
  âœ… alumni: 17 docs
  âœ… news: 18 docs
  âœ… publications: 32 docs
  âœ… lab_info: 1 docs
âœ… Hierarchical RAG ready!
 * Serving Flask app 'qwen3_4b_lowmem'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:4005
 * Running on http://203.253.25.165:4005
INFO:werkzeug:[33mPress CTRL+C to quit[0m
