#!/usr/bin/env python3
"""
AI Chatbot Comprehensive Test Suite
Tests 50 different questions and analyzes responses
"""

import requests
import json
import time
from datetime import datetime

# Test questions categorized by type
TEST_QUESTIONS = [
    # ë©¤ë²„ ê´€ë ¨ (10ê°œ)
    {"q": "ì´ì£¼í˜•ì´ë¼ëŠ” ì‚¬ëŒì´ ìˆì–´?", "expected_keywords": ["ì´ì£¼í˜•", "ì„ì‚¬", "í•™ìƒ"], "category": "member"},
    {"q": "íŒ€ êµ¬ì„±ì›ì€ ëˆ„êµ¬ì¸ê°€ìš”?", "expected_keywords": ["êµìˆ˜", "í•™ìƒ", "ì¸í„´"], "category": "member"},
    {"q": "ì„ì‚¬ê³¼ì • í•™ìƒì€ ëª‡ ëª…ì¸ê°€ìš”?", "expected_keywords": ["ì„ì‚¬", "10", "ëª…"], "category": "member"},
    {"q": "ë°•ì„±ìš© í•™ìƒ ì´ë©”ì¼ ì•Œë ¤ì£¼ì„¸ìš”", "expected_keywords": ["ejqdl010", "gmail"], "category": "member"},
    {"q": "ê¹€í¬ì› êµìˆ˜ë‹˜ ì´ë©”ì¼ì€?", "expected_keywords": ["hwkim", "ssu.ac.kr"], "category": "member"},
    {"q": "ì •í˜¸ì¬ë‹˜ ê¹ƒí—ˆë¸Œ ì£¼ì†ŒëŠ”?", "expected_keywords": ["github", "JEONG-HO-JAE"], "category": "member"},
    {"q": "ì´ì„¸ë¹ˆ í•™ìƒì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”", "expected_keywords": ["ì´ì„¸ë¹ˆ", "ì»´í“¨í„°", "ë¹„ì „"], "category": "member"},
    {"q": "ê¹€ë„ì› í•™ìƒ ì—°ë½ì²˜ëŠ”?", "expected_keywords": ["a01066304767"], "category": "member"},
    {"q": "ì—°êµ¬ ì¸í„´ì€ ëª‡ ëª…ì´ì—ìš”?", "expected_keywords": ["ì¸í„´", "11", "ëª…"], "category": "member"},
    {"q": "ìµœì˜ì¬ í•™ìƒ ì „ê³µì´ ë­ì˜ˆìš”?", "expected_keywords": ["í†µê³„", "Statistics"], "category": "member"},

    # êµìˆ˜/ì—°êµ¬ì‹¤ ì •ë³´ (10ê°œ)
    {"q": "ì—°êµ¬ì‹¤ ì´ë¦„ì´ ë­ì˜ˆìš”?", "expected_keywords": ["Reality Lab"], "category": "lab_info"},
    {"q": "Reality Labì€ ì–´ë””ì— ìˆë‚˜ìš”?", "expected_keywords": ["ì„œìš¸", "ë™ì‘êµ¬", "ìˆ­ì‹¤"], "category": "lab_info"},
    {"q": "ì—°êµ¬ì‹¤ ì „í™”ë²ˆí˜¸ ì•Œë ¤ì£¼ì„¸ìš”", "expected_keywords": ["820-0679"], "category": "lab_info"},
    {"q": "ê¹€í¬ì› êµìˆ˜ë‹˜ ì „ê³µì€?", "expected_keywords": ["ì»´í“¨í„°", "ë¹„ì „", "vision"], "category": "lab_info"},
    {"q": "ì—°êµ¬ì‹¤ì€ ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?", "expected_keywords": ["2023"], "category": "lab_info"},
    {"q": "Reality Lab ì£¼ì†Œê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?", "expected_keywords": ["ì‚¬ë‹¹ë¡œ", "105"], "category": "lab_info"},
    {"q": "ì–´ë–¤ ì—°êµ¬ë¥¼ í•˜ë‚˜ìš”?", "expected_keywords": ["ì»´í“¨í„°", "ë¹„ì „", "AI"], "category": "lab_info"},
    {"q": "êµìˆ˜ë‹˜ ì†Œì†ì€?", "expected_keywords": ["Global School of Media", "ë¯¸ë””ì–´"], "category": "lab_info"},
    {"q": "ì—°êµ¬ì‹¤ ìœ„ì¹˜ ì•Œë ¤ì£¼ì„¸ìš”", "expected_keywords": ["ì„œìš¸", "ìˆ­ì‹¤"], "category": "lab_info"},
    {"q": "ì§€ë„ êµìˆ˜ë‹˜ì€ ëˆ„êµ¬ì„¸ìš”?", "expected_keywords": ["ê¹€í¬ì›"], "category": "lab_info"},

    # ì—°êµ¬ ì£¼ì œ (10ê°œ)
    {"q": "ì–´ë–¤ ë¶„ì•¼ë¥¼ ì—°êµ¬í•˜ë‚˜ìš”?", "expected_keywords": ["ì»´í“¨í„°", "ë¹„ì „", "ë”¥ëŸ¬ë‹", "AI"], "category": "research"},
    {"q": "ë¡œë³´í‹±ìŠ¤ ì—°êµ¬ë„ í•˜ë‚˜ìš”?", "expected_keywords": ["ë¡œë³´í‹±ìŠ¤", "Robotics"], "category": "research"},
    {"q": "ë°•ì„±ìš© í•™ìƒ ì—°êµ¬ ì£¼ì œëŠ”?", "expected_keywords": ["Image Restoration", "Astronomy"], "category": "research"},
    {"q": "ì´ìƒë¯¼ í•™ìƒì€ ë¬´ìŠ¨ ì—°êµ¬í•´ìš”?", "expected_keywords": ["Embodied AI", "Computer Vision"], "category": "research"},
    {"q": "ì˜ë£Œ AI ì—°êµ¬ë„ í•˜ë‚˜ìš”?", "expected_keywords": ["ì˜ë£Œ", "Medical", "AI"], "category": "research"},
    {"q": "3D ë¹„ì „ ì—°êµ¬í•˜ëŠ” í•™ìƒ ìˆì–´ìš”?", "expected_keywords": ["ê³ ë¯¼ì£¼", "Minjoo"], "category": "research"},
    {"q": "ìƒì„± ëª¨ë¸ ì—°êµ¬ëŠ” ëˆ„ê°€ í•´ìš”?", "expected_keywords": ["Generative", "ìƒì„±"], "category": "research"},
    {"q": "ìŠ¤í¬ì¸  AI ì—°êµ¬ ìˆë‚˜ìš”?", "expected_keywords": ["Sports", "ìŠ¤í¬ì¸ "], "category": "research"},
    {"q": "ë©€í‹°ëª¨ë‹¬ ì—°êµ¬ í•˜ì‹œë‚˜ìš”?", "expected_keywords": ["Multimodal", "ë©€í‹°ëª¨ë‹¬"], "category": "research"},
    {"q": "ë”¥ëŸ¬ë‹ ì—°êµ¬í•˜ëŠ” í•™ìƒì€?", "expected_keywords": ["Deep Learning", "ë”¥ëŸ¬ë‹"], "category": "research"},

    # ë…¼ë¬¸/ì—…ì  (10ê°œ)
    {"q": "CVPR 2025ì— ë…¼ë¬¸ì´ ìˆë‚˜ìš”?", "expected_keywords": ["CVPR", "2025", "DynScene"], "category": "publication"},
    {"q": "ìµœê·¼ ë°œí‘œí•œ ë…¼ë¬¸ì€?", "expected_keywords": ["2025", "CVPR", "AAAI"], "category": "publication"},
    {"q": "AAAIì— ë…¼ë¬¸ ëƒˆì–´ìš”?", "expected_keywords": ["AAAI", "SIDL"], "category": "publication"},
    {"q": "Embodied AI ê´€ë ¨ ë…¼ë¬¸ ìˆì–´ìš”?", "expected_keywords": ["DynScene", "Embodied"], "category": "publication"},
    {"q": "1ë“± ìˆ˜ìƒí•œ ì  ìˆë‚˜ìš”?", "expected_keywords": ["1st", "ARNOLD", "Challenge"], "category": "publication"},
    {"q": "êµ­ì œ í•™íšŒ ë…¼ë¬¸ì´ ëª‡ ê°œì˜ˆìš”?", "expected_keywords": ["CVPR", "ICCV", "AAAI"], "category": "publication"},
    {"q": "TPAMI ì €ë„ ë…¼ë¬¸ ìˆë‚˜ìš”?", "expected_keywords": ["TPAMI"], "category": "publication"},
    {"q": "2025ë…„ ë…¼ë¬¸ì€?", "expected_keywords": ["2025", "CVPR", "AAAI"], "category": "publication"},
    {"q": "Image Restoration ë…¼ë¬¸ ìˆì–´ìš”?", "expected_keywords": ["Image Restoration", "SIDL"], "category": "publication"},
    {"q": "ìµœê·¼ ì—°êµ¬ ì„±ê³¼ëŠ”?", "expected_keywords": ["CVPR", "AAAI", "2025"], "category": "publication"},

    # ì§€ì›/ì°¸ì—¬ (10ê°œ)
    {"q": "ì—°êµ¬ì‹¤ì— ì§€ì›í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?", "expected_keywords": ["ì§€ì›", "ë¬¸ì˜", "ì—°ë½"], "category": "recruitment"},
    {"q": "ì„ì‚¬ ê³¼ì • ì§€ì› ë°©ë²•ì€?", "expected_keywords": ["ì„ì‚¬", "ì§€ì›", "ë¬¸ì˜"], "category": "recruitment"},
    {"q": "ì¸í„´ ëª¨ì§‘í•˜ë‚˜ìš”?", "expected_keywords": ["ì¸í„´", "ëª¨ì§‘"], "category": "recruitment"},
    {"q": "í•™ë¶€ìƒë„ ì°¸ì—¬í•  ìˆ˜ ìˆë‚˜ìš”?", "expected_keywords": ["í•™ë¶€", "ì¸í„´"], "category": "recruitment"},
    {"q": "ì–´ë–¤ í•™ìƒì„ ì„ í˜¸í•˜ë‚˜ìš”?", "expected_keywords": ["ì»´í“¨í„°", "ë¹„ì „", "ë”¥ëŸ¬ë‹"], "category": "recruitment"},
    {"q": "ì§€ì› ìê²©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?", "expected_keywords": ["ì»´í“¨í„°", "AI"], "category": "recruitment"},
    {"q": "ì—°ë½ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?", "expected_keywords": ["hwkim", "ssu.ac.kr", "820-0679"], "category": "recruitment"},
    {"q": "ë©´ì ‘ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?", "expected_keywords": ["ë¬¸ì˜", "ì—°ë½"], "category": "recruitment"},
    {"q": "í•„ìš”í•œ ìŠ¤í‚¬ì´ ë­ì˜ˆìš”?", "expected_keywords": ["ë”¥ëŸ¬ë‹", "ì»´í“¨í„°", "ë¹„ì „"], "category": "recruitment"},
    {"q": "êµìˆ˜ë‹˜ê»˜ ì–´ë–»ê²Œ ì—°ë½ë“œë¦¬ë‚˜ìš”?", "expected_keywords": ["hwkim", "ssu.ac.kr"], "category": "recruitment"},
]

def test_question(question, server_url="http://localhost:4005/chat"):
    """Test a single question and return the response"""
    try:
        response = requests.post(
            server_url,
            json={"question": question["q"]},
            headers={"Content-Type": "application/json"},
            timeout=60
        )
        response.raise_for_status()
        data = response.json()
        return {
            "question": question["q"],
            "category": question["category"],
            "expected_keywords": question["expected_keywords"],
            "response": data.get("response", ""),
            "response_time": data.get("response_time", 0),
            "tokens": data.get("tokens", 0),
            "error": None
        }
    except Exception as e:
        return {
            "question": question["q"],
            "category": question["category"],
            "expected_keywords": question["expected_keywords"],
            "response": "",
            "response_time": 0,
            "tokens": 0,
            "error": str(e)
        }

def analyze_response(result):
    """Analyze if response is acceptable"""
    response = result["response"].lower()
    expected = result["expected_keywords"]

    # Check for error
    if result["error"]:
        return {
            "status": "ERROR",
            "reason": result["error"],
            "matched_keywords": []
        }

    # Check for empty response
    if not response or len(response.strip()) < 10:
        return {
            "status": "FAIL",
            "reason": "ì‘ë‹µì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ìŒ",
            "matched_keywords": []
        }

    # Check for error messages in response
    error_phrases = ["ì˜¤ë¥˜ê°€ ë°œìƒ", "ì£„ì†¡í•©ë‹ˆë‹¤", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ë‹¤ì‹œ ì‹œë„"]
    if any(phrase in response for phrase in error_phrases):
        return {
            "status": "FAIL",
            "reason": "ì˜¤ë¥˜ ì‘ë‹µ",
            "matched_keywords": []
        }

    # Check for internal reasoning (hallucination)
    bad_patterns = ["ì°¸ê³ ìë£Œ 1", "ì°¸ê³ ìë£Œ 2", "ì •ë‹µ:", "ì§ˆë¬¸:", "---", "**ì •ë‹µ**", "looking at reference"]
    if any(pattern.lower() in response for pattern in bad_patterns):
        return {
            "status": "WARN",
            "reason": "ë‚´ë¶€ ì¶”ë¡  ê³¼ì • í¬í•¨",
            "matched_keywords": []
        }

    # Check keyword matching
    matched = []
    for keyword in expected:
        if keyword.lower() in response:
            matched.append(keyword)

    match_rate = len(matched) / len(expected) if expected else 0

    if match_rate >= 0.5:  # At least 50% keywords matched
        return {
            "status": "PASS",
            "reason": f"í‚¤ì›Œë“œ ë§¤ì¹­ {match_rate*100:.0f}%",
            "matched_keywords": matched
        }
    else:
        return {
            "status": "FAIL",
            "reason": f"í‚¤ì›Œë“œ ë§¤ì¹­ ë¶€ì¡± ({match_rate*100:.0f}%)",
            "matched_keywords": matched
        }

def run_tests():
    """Run all tests and generate report"""
    print("=" * 80)
    print("AI Chatbot Comprehensive Test - 50 Questions")
    print("=" * 80)
    print(f"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    results = []
    total = len(TEST_QUESTIONS)

    for i, question in enumerate(TEST_QUESTIONS, 1):
        print(f"[{i}/{total}] Testing: {question['q'][:50]}...")
        result = test_question(question)
        analysis = analyze_response(result)

        result["analysis"] = analysis
        results.append(result)

        # Print status
        status_symbol = {
            "PASS": "âœ…",
            "WARN": "âš ï¸",
            "FAIL": "âŒ",
            "ERROR": "ğŸš¨"
        }
        symbol = status_symbol.get(analysis["status"], "â“")
        print(f"   {symbol} {analysis['status']}: {analysis['reason']}")

        # Small delay between requests
        time.sleep(1)

    # Generate summary
    print("\n" + "=" * 80)
    print("TEST SUMMARY")
    print("=" * 80)

    status_counts = {"PASS": 0, "WARN": 0, "FAIL": 0, "ERROR": 0}
    for result in results:
        status = result["analysis"]["status"]
        status_counts[status] = status_counts.get(status, 0) + 1

    print(f"Total Questions: {total}")
    print(f"âœ… PASS: {status_counts['PASS']} ({status_counts['PASS']/total*100:.1f}%)")
    print(f"âš ï¸  WARN: {status_counts['WARN']} ({status_counts['WARN']/total*100:.1f}%)")
    print(f"âŒ FAIL: {status_counts['FAIL']} ({status_counts['FAIL']/total*100:.1f}%)")
    print(f"ğŸš¨ ERROR: {status_counts['ERROR']} ({status_counts['ERROR']/total*100:.1f}%)")

    # Category breakdown
    print("\n" + "-" * 80)
    print("CATEGORY BREAKDOWN")
    print("-" * 80)

    categories = {}
    for result in results:
        cat = result["category"]
        if cat not in categories:
            categories[cat] = {"PASS": 0, "WARN": 0, "FAIL": 0, "ERROR": 0, "total": 0}
        categories[cat][result["analysis"]["status"]] += 1
        categories[cat]["total"] += 1

    for cat, counts in sorted(categories.items()):
        pass_rate = counts["PASS"] / counts["total"] * 100
        print(f"{cat:15s}: {counts['PASS']}/{counts['total']} passed ({pass_rate:.0f}%)")

    # Failed questions detail
    failed = [r for r in results if r["analysis"]["status"] in ["FAIL", "ERROR"]]
    if failed:
        print("\n" + "-" * 80)
        print("FAILED QUESTIONS DETAIL")
        print("-" * 80)
        for result in failed:
            print(f"\nì§ˆë¬¸: {result['question']}")
            print(f"ìƒíƒœ: {result['analysis']['status']}")
            print(f"ì´ìœ : {result['analysis']['reason']}")
            print(f"ì‘ë‹µ: {result['response'][:200]}...")

    # Warning questions
    warned = [r for r in results if r["analysis"]["status"] == "WARN"]
    if warned:
        print("\n" + "-" * 80)
        print("WARNING QUESTIONS (Internal Reasoning)")
        print("-" * 80)
        for result in warned:
            print(f"\nì§ˆë¬¸: {result['question']}")
            print(f"ì‘ë‹µ: {result['response'][:200]}...")

    # Final verdict
    print("\n" + "=" * 80)
    pass_rate = (status_counts["PASS"] + status_counts["WARN"]) / total * 100

    if status_counts["PASS"] >= 45:  # 90% pass
        print("ğŸ‰ TEST PASSED! Ready to deploy.")
        verdict = "PASS"
    elif pass_rate >= 40:  # 80% acceptable
        print("âš ï¸  TEST ACCEPTABLE. Some issues need attention.")
        verdict = "ACCEPTABLE"
    else:
        print("âŒ TEST FAILED! Significant issues found.")
        verdict = "FAIL"

    print("=" * 80)

    # Save detailed results
    with open("/home/i0179/Realitylab-site/ai_server/test_results.json", "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "summary": status_counts,
            "verdict": verdict,
            "results": results
        }, f, ensure_ascii=False, indent=2)

    print(f"\nDetailed results saved to: ai_server/test_results.json")

    return verdict, status_counts

if __name__ == "__main__":
    verdict, counts = run_tests()
    exit(0 if verdict == "PASS" else 1)
