#!/usr/bin/env python3
"""
AI Chatbot Realistic Test Suite
Based on actual homepage content
Tests 30 realistic questions with proper delays to avoid concurrency issues
"""

import requests
import json
import time
from datetime import datetime

# Test questions based on ACTUAL homepage content
TEST_QUESTIONS = [
    # êµìˆ˜/ì—°êµ¬ì‹¤ ê¸°ë³¸ ì •ë³´ (7ê°œ)
    {
        "q": "ì—°êµ¬ì‹¤ ì´ë¦„ì´ ë­ì˜ˆìš”?",
        "expected_keywords": ["Reality Lab", "SSU"],
        "category": "lab_info"
    },
    {
        "q": "ê¹€í¬ì› êµìˆ˜ë‹˜ ì´ë©”ì¼ ì£¼ì†Œ ì•Œë ¤ì£¼ì„¸ìš”",
        "expected_keywords": ["hwkim", "ssu.ac.kr"],
        "category": "lab_info"
    },
    {
        "q": "ì—°êµ¬ì‹¤ ì „í™”ë²ˆí˜¸ëŠ”?",
        "expected_keywords": ["820-0679", "02"],
        "category": "lab_info"
    },
    {
        "q": "êµìˆ˜ë‹˜ì´ ì–´ëŠ í•™ê³¼ ì†Œì†ì´ì—ìš”?",
        "expected_keywords": ["Global School of Media", "ë¯¸ë””ì–´"],
        "category": "lab_info"
    },
    {
        "q": "ì—°êµ¬ì‹¤ì€ ì–¸ì œ ë§Œë“¤ì–´ì¡Œë‚˜ìš”?",
        "expected_keywords": ["2023"],
        "category": "lab_info"
    },
    {
        "q": "Reality Labì€ ì–´ë–¤ ì—°êµ¬ë¥¼ í•˜ë‚˜ìš”?",
        "expected_keywords": ["computer vision", "robotics", "AI", "ë¹„ì „"],
        "category": "lab_info"
    },
    {
        "q": "ê¹€í¬ì› êµìˆ˜ë‹˜ êµ¬ê¸€ ìŠ¤ì¹¼ë¼ ì£¼ì†Œ ìˆë‚˜ìš”?",
        "expected_keywords": ["google", "scholar", "citations"],
        "category": "lab_info"
    },

    # ì„ì‚¬ í•™ìƒ ì •ë³´ (8ê°œ)
    {
        "q": "ì„ì‚¬ê³¼ì • í•™ìƒì€ ëª‡ ëª…ì¸ê°€ìš”?",
        "expected_keywords": ["10", "ì„ì‚¬", "ëª…"],
        "category": "member"
    },
    {
        "q": "ë°•ì„±ìš© í•™ìƒì€ ì–´ë–¤ ì—°êµ¬ë¥¼ í•´ìš”?",
        "expected_keywords": ["Image Restoration", "Astronomy", "ì²œë¬¸"],
        "category": "member"
    },
    {
        "q": "ì´ìƒë¯¼ í•™ìƒ ì´ë©”ì¼ ì£¼ì†ŒëŠ”?",
        "expected_keywords": ["sm32289", "gmail"],
        "category": "member"
    },
    {
        "q": "Embodied AI ì—°êµ¬í•˜ëŠ” í•™ìƒ ìˆì–´ìš”?",
        "expected_keywords": ["ì´ìƒë¯¼", "Sangmin"],
        "category": "member"
    },
    {
        "q": "ê³ ë¯¼ì£¼ í•™ìƒ ì „ê³µì´ ë­ì˜ˆìš”?",
        "expected_keywords": ["Data Science", "ë°ì´í„°", "ì„¸ì¢…"],
        "category": "member"
    },
    {
        "q": "ì •í˜¸ì¬ í•™ìƒ ê¹ƒí—ˆë¸Œ ì£¼ì†ŒëŠ”?",
        "expected_keywords": ["github", "JEONG-HO-JAE"],
        "category": "member"
    },
    {
        "q": "Multimodal Learning ì—°êµ¬í•˜ëŠ” í•™ìƒì€?",
        "expected_keywords": ["ê³ í˜„ì„œ", "Hyunsuh"],
        "category": "member"
    },
    {
        "q": "ì´ì£¼í˜• í•™ìƒì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
        "expected_keywords": ["ì´ì£¼í˜•", "ì„ì‚¬", "Computer Vision"],
        "category": "member"
    },

    # ì¸í„´ ì •ë³´ (4ê°œ)
    {
        "q": "ì—°êµ¬ ì¸í„´ì€ ëª‡ ëª…ì´ì—ìš”?",
        "expected_keywords": ["11", "ì¸í„´", "ëª…"],
        "category": "member"
    },
    {
        "q": "Medical AI ì—°êµ¬í•˜ëŠ” í•™ìƒ ìˆë‚˜ìš”?",
        "expected_keywords": ["ê¹€ì„œì˜", "ê¹€ì˜ˆë¦¬", "Seoyoung", "Yeri"],
        "category": "member"
    },
    {
        "q": "ì´ì„¸ë¹ˆ í•™ìƒ ì—°ë½ì²˜ ì•Œë ¤ì£¼ì„¸ìš”",
        "expected_keywords": ["jnf0219", "naver"],
        "category": "member"
    },
    {
        "q": "Language Model ì—°êµ¬í•˜ëŠ” í•™ìƒì€?",
        "expected_keywords": ["ì†¡ì€ìš°", "Eunwoo"],
        "category": "member"
    },

    # ë…¼ë¬¸/ì—…ì  (8ê°œ)
    {
        "q": "CVPR 2025ì— acceptëœ ë…¼ë¬¸ ìˆë‚˜ìš”?",
        "expected_keywords": ["DynScene", "CVPR", "2025"],
        "category": "publication"
    },
    {
        "q": "DynScene ë…¼ë¬¸ì´ ë­ì˜ˆìš”?",
        "expected_keywords": ["robotic", "manipulation", "embodied"],
        "category": "publication"
    },
    {
        "q": "AAAI 2025 ë…¼ë¬¸ì€ ì–´ë–¤ ê±°ì˜ˆìš”?",
        "expected_keywords": ["SIDL", "smartphone", "image"],
        "category": "publication"
    },
    {
        "q": "SIDLì´ ë­”ê°€ìš”?",
        "expected_keywords": ["smartphone", "dirty", "lens", "restoration"],
        "category": "publication"
    },
    {
        "q": "BMVC 2025ì—ë„ ë…¼ë¬¸ ëƒˆì–´ìš”?",
        "expected_keywords": ["BMVC", "transformation", "diffusion"],
        "category": "publication"
    },
    {
        "q": "ì˜ë£Œ ê´€ë ¨ ë…¼ë¬¸ ìˆë‚˜ìš”?",
        "expected_keywords": ["DeepGAM", "depression", "PLOS", "dog cough"],
        "category": "publication"
    },
    {
        "q": "2025ë…„ì— ë°œí‘œí•œ ë…¼ë¬¸ì€ ëª‡ ê°œì˜ˆìš”?",
        "expected_keywords": ["2025", "CVPR", "AAAI", "BMVC"],
        "category": "publication"
    },
    {
        "q": "3D Vision ê´€ë ¨ ë…¼ë¬¸ ìˆì–´ìš”?",
        "expected_keywords": ["radiance", "style transfer", "APP3DV"],
        "category": "publication"
    },

    # ì§€ì›/ì°¸ì—¬ (3ê°œ)
    {
        "q": "ì—°êµ¬ì‹¤ì— ì§€ì›í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
        "expected_keywords": ["ì—°ë½", "ë¬¸ì˜", "êµìˆ˜", "ì´ë©”ì¼"],
        "category": "recruitment"
    },
    {
        "q": "ì—°êµ¬ì‹¤ ì—°ë½ì²˜ ì•Œë ¤ì£¼ì„¸ìš”",
        "expected_keywords": ["hwkim", "820-0679", "ssu.ac.kr"],
        "category": "recruitment"
    },
    {
        "q": "ì–´ë–¤ ë¶„ì•¼ë¥¼ ì—°êµ¬í•˜ëŠ” í•™ìƒì„ ì°¾ë‚˜ìš”?",
        "expected_keywords": ["computer vision", "deep learning", "AI", "robotics"],
        "category": "recruitment"
    },
]

def test_question(question, server_url="http://localhost:4005/chat"):
    """Test a single question and return the response"""
    try:
        response = requests.post(
            server_url,
            json={"question": question["q"]},
            headers={"Content-Type": "application/json"},
            timeout=60
        )
        response.raise_for_status()
        data = response.json()

        # Check for "waiting" status
        if data.get('status') == 'waiting':
            return {
                "question": question["q"],
                "category": question["category"],
                "expected_keywords": question["expected_keywords"],
                "response": data.get("response", ""),
                "response_time": 0,
                "tokens": 0,
                "error": "Server busy (concurrency limit)"
            }

        return {
            "question": question["q"],
            "category": question["category"],
            "expected_keywords": question["expected_keywords"],
            "response": data.get("response", ""),
            "response_time": data.get("response_time", 0),
            "tokens": data.get("tokens", 0),
            "error": None
        }
    except Exception as e:
        return {
            "question": question["q"],
            "category": question["category"],
            "expected_keywords": question["expected_keywords"],
            "response": "",
            "response_time": 0,
            "tokens": 0,
            "error": str(e)
        }

def analyze_response(result):
    """Analyze if response is acceptable"""
    response = result["response"].lower()
    expected = result["expected_keywords"]

    # Check for error
    if result["error"]:
        return {
            "status": "ERROR",
            "reason": result["error"],
            "matched_keywords": []
        }

    # Check for empty response
    if not response or len(response.strip()) < 10:
        return {
            "status": "FAIL",
            "reason": "ì‘ë‹µì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ìŒ",
            "matched_keywords": []
        }

    # Check for error messages in response
    error_phrases = ["ì˜¤ë¥˜ê°€ ë°œìƒ", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ë‹¤ì‹œ ì‹œë„", "currently talking"]
    if any(phrase in response for phrase in error_phrases):
        return {
            "status": "FAIL",
            "reason": "ì˜¤ë¥˜ ì‘ë‹µ",
            "matched_keywords": []
        }

    # Check for internal reasoning (hallucination)
    bad_patterns = ["ì°¸ê³ ìë£Œ 1", "ì°¸ê³ ìë£Œ 2", "ì •ë‹µ:", "ì§ˆë¬¸:", "---", "**ì •ë‹µ**", "looking at reference", "[ì°¸ê³ ìë£Œ", "[ì°¸ì¡°ìë£Œ"]
    if any(pattern.lower() in response for pattern in bad_patterns):
        return {
            "status": "WARN",
            "reason": "ë‚´ë¶€ ì¶”ë¡  ê³¼ì • í¬í•¨",
            "matched_keywords": []
        }

    # Check keyword matching
    matched = []
    for keyword in expected:
        if keyword.lower() in response:
            matched.append(keyword)

    match_rate = len(matched) / len(expected) if expected else 0

    if match_rate >= 0.5:  # At least 50% keywords matched
        return {
            "status": "PASS",
            "reason": f"í‚¤ì›Œë“œ ë§¤ì¹­ {match_rate*100:.0f}%",
            "matched_keywords": matched
        }
    else:
        return {
            "status": "FAIL",
            "reason": f"í‚¤ì›Œë“œ ë§¤ì¹­ ë¶€ì¡± ({match_rate*100:.0f}%)",
            "matched_keywords": matched
        }

def run_tests():
    """Run all tests and generate report"""
    print("=" * 80)
    print("AI Chatbot Realistic Test - 30 Questions (Sequential)")
    print("Based on actual homepage content")
    print("=" * 80)
    print(f"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    results = []
    total = len(TEST_QUESTIONS)

    for i, question in enumerate(TEST_QUESTIONS, 1):
        print(f"[{i}/{total}] Testing: {question['q']}")
        result = test_question(question)
        analysis = analyze_response(result)

        result["analysis"] = analysis
        results.append(result)

        # Print status
        status_symbol = {
            "PASS": "âœ…",
            "WARN": "âš ï¸",
            "FAIL": "âŒ",
            "ERROR": "ğŸš¨"
        }
        symbol = status_symbol.get(analysis["status"], "â“")
        print(f"   {symbol} {analysis['status']}: {analysis['reason']}")
        print(f"   Response time: {result['response_time']:.2f}s")

        # Wait between requests to avoid concurrency issues
        if i < total:
            time.sleep(2)  # 2 second delay between requests

    # Generate summary
    print("\n" + "=" * 80)
    print("TEST SUMMARY")
    print("=" * 80)

    status_counts = {"PASS": 0, "WARN": 0, "FAIL": 0, "ERROR": 0}
    for result in results:
        status = result["analysis"]["status"]
        status_counts[status] = status_counts.get(status, 0) + 1

    print(f"Total Questions: {total}")
    print(f"âœ… PASS: {status_counts['PASS']} ({status_counts['PASS']/total*100:.1f}%)")
    print(f"âš ï¸  WARN: {status_counts['WARN']} ({status_counts['WARN']/total*100:.1f}%)")
    print(f"âŒ FAIL: {status_counts['FAIL']} ({status_counts['FAIL']/total*100:.1f}%)")
    print(f"ğŸš¨ ERROR: {status_counts['ERROR']} ({status_counts['ERROR']/total*100:.1f}%)")

    # Category breakdown
    print("\n" + "-" * 80)
    print("CATEGORY BREAKDOWN")
    print("-" * 80)

    categories = {}
    for result in results:
        cat = result["category"]
        if cat not in categories:
            categories[cat] = {"PASS": 0, "WARN": 0, "FAIL": 0, "ERROR": 0, "total": 0}
        categories[cat][result["analysis"]["status"]] += 1
        categories[cat]["total"] += 1

    for cat, counts in sorted(categories.items()):
        pass_rate = counts["PASS"] / counts["total"] * 100
        print(f"{cat:15s}: {counts['PASS']}/{counts['total']} passed ({pass_rate:.0f}%)")

    # Failed questions detail
    failed = [r for r in results if r["analysis"]["status"] in ["FAIL", "ERROR"]]
    if failed:
        print("\n" + "-" * 80)
        print(f"FAILED QUESTIONS ({len(failed)} total)")
        print("-" * 80)
        for result in failed[:10]:  # Show first 10
            print(f"\nì§ˆë¬¸: {result['question']}")
            print(f"ìƒíƒœ: {result['analysis']['status']}")
            print(f"ì´ìœ : {result['analysis']['reason']}")
            if result['response']:
                print(f"ì‘ë‹µ: {result['response'][:150]}...")

    # Warning questions
    warned = [r for r in results if r["analysis"]["status"] == "WARN"]
    if warned:
        print("\n" + "-" * 80)
        print(f"WARNING QUESTIONS ({len(warned)} total)")
        print("-" * 80)
        for result in warned[:5]:  # Show first 5
            print(f"\nì§ˆë¬¸: {result['question']}")
            print(f"ì‘ë‹µ: {result['response'][:150]}...")

    # Final verdict
    print("\n" + "=" * 80)
    acceptable_rate = (status_counts["PASS"] + status_counts["WARN"]) / total * 100

    if status_counts["PASS"] >= 27:  # 90% pass
        print("ğŸ‰ TEST PASSED! Chatbot is working well.")
        verdict = "PASS"
    elif acceptable_rate >= 24:  # 80% acceptable
        print("âš ï¸  TEST ACCEPTABLE. Some improvements recommended.")
        verdict = "ACCEPTABLE"
    else:
        print("âŒ TEST FAILED! Significant issues found.")
        verdict = "FAIL"

    print("=" * 80)

    # Save detailed results
    with open("/home/i0179/Realitylab-site/ai_server/test_results_v2.json", "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "summary": status_counts,
            "verdict": verdict,
            "results": results
        }, f, ensure_ascii=False, indent=2)

    print(f"\nDetailed results saved to: ai_server/test_results_v2.json")

    return verdict, status_counts

if __name__ == "__main__":
    verdict, counts = run_tests()
    exit(0 if verdict in ["PASS", "ACCEPTABLE"] else 1)
